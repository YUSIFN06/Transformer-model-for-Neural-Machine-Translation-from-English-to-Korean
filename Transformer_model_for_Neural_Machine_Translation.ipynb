{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6ZUy6q1WAo6k"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, Input, Dropout, LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qgk8PsDVAyfu"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, k, d):\n",
    "    i = k // 2\n",
    "    angles = pos / 10000 ** (2 * i / d)\n",
    "\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "G86tRN56BBTK"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d):\n",
    "    angle_rads = get_angles(np.arange(positions)[:, np.newaxis],\n",
    "                            np.arange(d)[np.newaxis, :],\n",
    "                            d)\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2XkJY-5rJqsD"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(look_ahead_mask, dec_target_padding_mask)\n",
    "\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Vr1_NB3zCxzS"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "      q, k, v must have matching leading dimensions.\n",
    "      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "      The mask has different shapes depending on its type(padding or look ahead)\n",
    "      but it must be broadcastable for addition.\n",
    "\n",
    "    Arguments:\n",
    "        q -- query shape == (..., seq_len_q, depth)\n",
    "        k -- key shape == (..., seq_len_k, depth)\n",
    "        v -- value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable\n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        output -- attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (1 - mask) * (-1e9)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9kv7rmHPDMjD"
   },
   "outputs": [],
   "source": [
    "def FullyConnected(embedding_dim, fully_connected_dim):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(embedding_dim)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E95PGj-3DP2l"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The encoder layer is composed by a multi-head self-attention mechanism,\n",
    "    followed by a simple, positionwise fully connected feed-forward network.\n",
    "    This architecture includes a residual connection around each of the two\n",
    "    sub-layers, followed by layer normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(num_heads=num_heads,\n",
    "                                      key_dim=embedding_dim,\n",
    "                                      dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FullyConnected(embedding_dim=embedding_dim,\n",
    "                                  fully_connected_dim=fully_connected_dim)\n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer\n",
    "\n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask -- Boolean mask to ensure that the padding is not\n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            encoder_layer_out -- Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        self_mha_output = self.mha(query=x, value=x, key=x, attention_mask=mask, training=training)\n",
    "\n",
    "        skip_x_attention = self.layernorm1(x + self_mha_output)\n",
    "\n",
    "        ffn_output = self.ffn(skip_x_attention)\n",
    "\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "\n",
    "        encoder_layer_out = self.layernorm2(skip_x_attention + ffn_output)\n",
    "\n",
    "        return encoder_layer_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "12PYfXoGDogQ"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the input to an embedding layer\n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    encoder Layers\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = Embedding(input_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                                self.embedding_dim)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps)\n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder\n",
    "\n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, input_seq_len)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask -- Boolean mask to ensure that the padding is not\n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            x -- Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z53A452XD7dQ"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The decoder layer is composed by two multi-head attention blocks,\n",
    "    one that takes the new input and uses self-attention, and the other\n",
    "    one that combines it with the output of the encoder, followed by a\n",
    "    fully connected block.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(num_heads=num_heads,\n",
    "                                      key_dim=embedding_dim,\n",
    "                                      dropout=dropout_rate)\n",
    "\n",
    "        self.mha2 = MultiHeadAttention(num_heads=num_heads,\n",
    "                                      key_dim=embedding_dim,\n",
    "                                      dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FullyConnected(embedding_dim=embedding_dim,\n",
    "                                  fully_connected_dim=fully_connected_dim)\n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm3 = LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Decoder Layer\n",
    "\n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)\n",
    "            enc_output --  Tensor of shape(batch_size, input_seq_len, embedding_dim)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask -- Boolean mask for the target_input\n",
    "            padding_mask -- Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            out3 -- Tensor of shape (batch_size, target_seq_len, embedding_dim)\n",
    "            attn_weights_block1 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "            attn_weights_block2 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        mult_attn_out1, attn_weights_block1 = self.mha1(query=x, value=x, key=x, attention_mask=look_ahead_mask, return_attention_scores=True)\n",
    "        Q1 = self.layernorm1(x + mult_attn_out1)\n",
    "\n",
    "        mult_attn_out2, attn_weights_block2 = self.mha2(query=Q1, value=enc_output, key=enc_output, attention_mask=padding_mask, return_attention_scores=True)\n",
    "\n",
    "        ffn_output = self.ffn(mult_attn_out2)\n",
    "\n",
    "        ffn_output = self.dropout_ffn(ffn_output)\n",
    "\n",
    "        out3 = self.layernorm3(mult_attn_out2 + ffn_output)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_epd6UdsEJY8"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the target input to an embedding layer\n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    decoder Layers\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = Embedding(target_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.embedding_dim)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps)\n",
    "                           for _ in range(self.num_layers)]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward  pass for the Decoder\n",
    "\n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)\n",
    "            enc_output --  Tensor of shape(batch_size, input_seq_len, embedding_dim)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask -- Boolean mask for the target_input\n",
    "            padding_mask -- Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)\n",
    "            attention_weights - Dictionary of tensors containing all the attention weights\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training=training,\n",
    "                                                 look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1_self_att'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2_decenc_att'.format(i+1)] = block2\n",
    "\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AnA72ZVgEhMg"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Complete transformer with an Encoder and a Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size,\n",
    "               target_vocab_size, max_positional_encoding_input,\n",
    "               max_positional_encoding_target, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers=num_layers,\n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               input_vocab_size=input_vocab_size,\n",
    "                               maximum_position_encoding=max_positional_encoding_input,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers,\n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               target_vocab_size=target_vocab_size,\n",
    "                               maximum_position_encoding=max_positional_encoding_target,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.final_layer = Dense(target_vocab_size, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "      input_sentence, output_sentence = inputs\n",
    "\n",
    "      enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(input_sentence, output_sentence)\n",
    "\n",
    "      enc_output = self.encoder(input_sentence, training=training, mask=enc_padding_mask)\n",
    "      dec_output, attention_weights = self.decoder(\n",
    "          output_sentence, enc_output, training=training,\n",
    "          look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask\n",
    "      )\n",
    "\n",
    "      final_output = self.final_layer(dec_output)\n",
    "\n",
    "      return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "b8190eadfbaf48b2af2d53ae395de235",
      "ccf3c52605e94877b402a6d23e85aa69",
      "21d515489c6745dc9d3ec440918ccca4",
      "3cbac5f04913472bb12617d4a7b4b814",
      "d340936cf123463ea5116913e36dd3f7",
      "d6f5c5477f7e4d66a63a34d1fa0bcc58",
      "b74a62daed1e40a396089974feb1390e",
      "021c2c8d787e444db2a270550b840597",
      "9ddbc1ad82594f95ae45cea713da797b",
      "7f4714dce0ee449c847bb50588a5efe7",
      "9698961c032e4f0a92d823ddcdf35193",
      "9da678b51ca344e39a502d1d057107a3",
      "e9f83af62c9d403594145380dd8c227c",
      "b1f8d7ab447e462594a3508bc048a6ca",
      "5acf4d2b0bba4b3eb2561bbf8922559a",
      "c71e320c13e54f1984756c5565fb176b",
      "369347f3f9b54aff97b6dabbbee4dafe",
      "4575134c86754eea996a0216a8646648",
      "c6221478a11b4f64ab35507315f88510",
      "a0d2485ae9be443eadf02820e84ad349",
      "fe72fa91c28143b68586d44db84a023e",
      "02c8a77343ee4fc38d9e35d2c5092318",
      "934c3e00b26e46fb8ed59a9bf200ad89",
      "baa820e20be34a2fb58b1568575ed347",
      "d9c7219e76e94c3daa355268fca7b947",
      "0405a37be61a4134a1151f1b8e2a0414",
      "95cc47369989417182193182edede417",
      "6e66bf5b6fd84f89babeb1bd2588e667",
      "5497c3bd537d489f96750c788ab4b29a",
      "4da5f1e9a1fc4b17acc98a4f64f3546b",
      "e4a77a3e54e64043a5cf3ca2b33416a3",
      "90db52560068471caca4a75e08670b05",
      "21e0126bbb6648fa93179b9d3c70e091"
     ]
    },
    "id": "OjqthPLFE5Xn",
    "outputId": "04c6584d-d53f-4b4c-9f8d-26aa4cd7a5b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8190eadfbaf48b2af2d53ae395de235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/89.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da678b51ca344e39a502d1d057107a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "news_talk_en_ko_train_130000.tsv:   0%|          | 0.00/345M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934c3e00b26e46fb8ed59a9bf200ad89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1299999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"bongsoo/news_talk_en_ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8euataySE7vO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "df = df.rename(columns={\"Skinner's reward is mostly eye-watering.\": \"English\", \"스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.\": \"Korean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SYrqDZM2FA2i"
   },
   "outputs": [],
   "source": [
    "all_chars = ''.join(df['English'])\n",
    "\n",
    "result1 = ''.join(sorted(set(all_chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "onJJr-dbFFdI"
   },
   "outputs": [],
   "source": [
    "all_chars = ''.join(df['Korean'])\n",
    "\n",
    "result2 = ''.join(sorted(set(all_chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFz_pKzAFGGf",
    "outputId": "632f24f6-b40e-4524-c8d5-74429de4aae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz|~ £¥§¨¬­®°±²³´µ·¹º¼¾ÁÂÅÆÇÉÎÑÓÕÖ×ØÜÞàáâãäåæçèéêëìíîïðñòóôöøùúûüýāăąĆćČčĐēěğīĭİıŁłŌōŏőřŚŞşŠšũūŬůžơưǎǐǒǔǫǽțɾʻˈ˚̊ΔΛΟΠΩαβδθμСᝧḪṇạảầậặẻễịọỏốồổỗộớờợủứừỳỹ​‎‐‑–—―‘’“”•…‧‬‭′⁄₁₂₃₩€⃗℃℉ℓ№™⅓⅔ⅠⅡⅢⅩ∕∼≡ⓧ△○★☆♡♥➋➌➍➎➏「」『』いうかしろ・ㆍ㎃㎉㎍㎎㎏㎒㎓㎖㎘㎚㎛㎜㎝㎞㎠㎡㎢㎥㎸㎾㎿㏊一三上中久之九乳亂亡交享京人付令份伉低作來俱倉偉傳儷八公出列功勝北博古台史司吉吾命和唐啞國園團垠城報場士夏外夢大天夷妓妾娥婢子孝孫學安寒小山岩島川州平年度廣建德必恩情愛慷憑成所文新於旗日旭昇显時智曲書曾最有杆李東梁梅歲死殉殞殯殲毅母民水江汽沖治洞派流浪海港渾溪滅滴漠灣炫無然父物玄王理瓚生産畵癒着睛石砂社神祥票秘稷立納結經緣縣繩美義習老耳聖聞聾股臺與舞芳茶菅蘇號衆行街襄視觴記說謝象車轉车辰近逢進逸遊運采野金釣長长門附限陸隱雅集靑面頻風食香魚鷹黒點齋龍龙蘭ﬁﬂ️﻿＆－｢｣ﾎ￦\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz~ £¥§®°±²³·º¾ÇÎÓÕ×Øäçéøüİıŏşšž˚˜ΒΩδμᅟᅥᆪỏố​‐–―‘’“”•․…‧‪‬′‵₁₂€⃗℃℉ℓ™⅓⅔ⅠⅡⅢⅣⅥⅩ→∙∼≡≪≫ⓧ□△○★☆♡♥➡　〈〉《》「」『』〜〮いうかきしのはろ・ㄷㄹㅅㅆㅇㅈㅏㅔㅠㅡㆍ㈔㈜㍱㎃㎈㎉㎍㎎㎏㎐㎑㎒㎓㎔㎖㎗㎘㎚㎛㎜㎝㎞㎟㎠㎡㎢㎥㎧㎨㎩㎫㎳㎷㎸㎽㎾㎿㏃㏄㏈㏊㏏一丁七丈三上下不世丘中丸丹主丽乃久之乙九书乳亂事二云五井亘亞亡亢交亥亦享京亭亮人仁今从他付仙代令以仲任企伉伊伏休伸似位低住佐佑佛作佳使來例供侵俉俊保信修俯俱俵倉倍們倒候倚借倡倦倪倫假偉停健傅傘備傳傷僊像僑僕僞僧價儒儷允元兄充兆先光克免兎兒入內全兩八公六共兵具冀円冬冶凍凡凤凰凱出刀分刑列创初別利制刻剋前剛割創劃劇劉劍力功加助勅勇勒動務勝勞勢勸勿化北匠匡區十千升午卉半協南博占印却卵厚原去參友反取受叢口古句可台史右司各合吉同名向君吟吾呂告周呼命和哀品哈員哭哲唐唱商問啞善喆喘喜喪單嘉器嚴囚四回因固國圍園圓圖團土在地坂坐型垠城域基埼堀堂堅堤堯報場塔塞塼境墓墳壁壇壓壞士壺壽夏夕外多夜夢大天太夫失夷奄奇奈奎契奠奬奭女奸如妃妊妓妖妻妾始姑姓姙姦姬姮威娛娥婆婚婢婦媒媛媤嫌嫦子孔字存孝孟孤孫學宅宇守安宋宏宖宗官宙定宜客室宮害宴家宿寃寅密富寒察寡實寧審寬寶寸寺封射將專尊尋對導小少尙尚尤尹尺尿局居屋屍屑展屛屬山岐岑岡岩岸峙峨峯峰島崇崎崔崛嶺巖川州巡工巧巨差己巳巴巷市希帖帝帥師席帶常幣平年幸幻庄序店府度座庫庭庶康庸廈廛廟廣廬廳延廷建弊式弓引弟弱張强弼彈彌形彦彫彭彰影役彼往征待律後徒得徙從御復微徵德徽心必忍忖志忠快思怡急性怨恐恒恥恨恩恭悌悟悠患悲悸情惠惡想意愚愛感慈慕慨慮慵慶慷憂憑憤憲憾應懲戀戊戌成我戒戟戰戴戶房所手才扶承技抑投折抽拍拔拿指振捨授推揚換損搜携摩撲擇據攘攝支收改攻放政故敎敏救敗教敞散敦敬整敵敷數文斌斑斗料斥斬新斷方於施旅旋族旗旣日旨早旬旭时旺昇明易星春昨昭是時晃晉晋晚晦晩景智暑暗暴曲書曹曾最會月有服望朝期木未末本札朱朴杆杉李杏材村杖杞杨杭杯東松板林果枯柄柑染柳栗校株核根格案桓桶梁梅梓棄棋棍棒棘棟森棺植椒楊楚楡業極榜榮構槨槪樂模樸樹橋機橫檜檢欄權次欧欲歌歐止正此武歲歷歸死殉殊殞殯殲殺殿毁毅母毒比毖毛氏民氣水氷永汀汁求汉汎汝江池沈沒沖沙沫河油治沼況泉法波泣泥注泰洁洋洗洛洞津洪洲活派流浙浚浦浩浪浮浴海涉淀淑淡淨淫深淳淵淸淹淺渡港渴渾湃湖湘湯源溜溝溪溫滅滋滑滬滯滴滿漁漏演漠漢潘潭潮澄澎澤澳濂濟濤濱瀉瀋瀑瀟瀨瀼瀾灣火灰災炎炫烈烹無然煙照熊熟熱燃燈燒營爐爭爲父爽爾片牙牛牡牧物特犬犯狀狗猫獄獨獵獻玄玆玉王玗玩玲玹珍珠班現球理琿瑞璐環瓚甘生産用田由甲申电男町界畜略異畵當疆疎疏疑病症痔痕痛痰瘀癒癸發白百的皇皮盃盆益盛盜盧目直相省眉眞眼着睛督睦瞰矢矣知短石砂砲破硬碁碎碑確磬社祇祐神祠祥票祭禁禍禎福禧禪禮禹秀私秋科秒秘秦秩移稀稅程稚種稷稼稿穀穆積穩穴空窓窮窯立竝章童端竹笑笠第筆等筑答策管節範築篠篪簡籍米粉粗精糖系紀約紅紋納純紙素紫細終結絞給統經綠綬維綱網綿線緝締緣編縣總績繩繼續红网罰署羅羊美羞群義羽翎習翼耀老考者耆而耕耳耶耿聖聚聞聯聰聲職聽聾肅肉肝育肺胃背胎胞胡能脇脈脚脫腸膜膝膵膽臆臣臨自臭至致臺與興舊舌舍舞舟航船艦色芝花芳苏苟若苦英茂范茶草荒莉莊莫菅華菱菴萊萎萬落葉著葛葬蒸蓋蓮蔡薄薛薦薺藏藝藤藻蘇蘭虎虔處虛虞號蛋蛤蜜蝙蝠螺蟄血衆行術街衛衝衡衣表裂裏裕裴製襄襲西要覆覇見規視親覺覽觀角解觴言計討訓記訟訪設許訴評詞詠試詩話誌認誕誘語誠誤說調談請論謀謐謖謙謚謝謠謫謹識警議護讀變讐讓讚谷豆豊豚象貞負財貢貧貨貯貴買費賀賊賞賢賣賤質赟赤赴起超越趙足趾跨路身車軌軍軒軟載輔輕輸輿轉辭辰農迅迎近返迫追送逆通逞速造逢連週進逸逼遊運過道達遠適遵遷選遺避還邊邑邦邪邱郞郡部郭郵都鄕鄧鄭酌酒酬醒醫醬采里重野量金針釣釧鈺鉉銀銃銅銘鋪錄錐錠錢錦錨錫鍊鎭鏃鐘鐵鑄長門閉開閑間閣閥閹關阪防阳阿附陋降限陝院陣除陰陵陸陽隆階隣隨隱雁雄雅集雙離難雨雪雲雷電需震霜霞露霽靈靑靖靜非面韓韜音韻項順須頭頸頻額顔願顚類顯風飛食飮飯飾養餘館饗首香馬馳駐駕騰驗驚驛驪髓體高髥鬪鬱鬼魁魏魔魚魯鮮鯨鱗鳥鳳鳴鴨鵬鶴鷄鷹鷺鹿麗麝麵麻黃黎黑黒點黨鼓齋齒龍龜가각간갇갈갉감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰갱갸갹걀걍걔걘거걱건걷걸검겁것겄겅겆겉겊겋게겐겔겜겝겟겠겡겨격겪견결겸겹겼경곁계곗곘고곡곤곧골곪곯곰곱곳공곶과곽관괂괄괌괏광괘괜괭괴괵괸굉교굣굥구국군굳굴굵굶굼굽굿궁궂궃궈궉권궐궜궤궬궷귀귄귈귐귑귓규균귤그극근귿글긁금급긋긍기긱긴긷길김깁깃깄깅깊까깍깎깐깔깜깝깟깠깡깥깨깬깰깸깹깻깼깽꺄꺅꺌꺠꺼꺽꺾껀껄껌껍껏껐껑께껫껴꼈꼐꼬꼭꼰꼴꼼꼽꼿꽁꽂꽃꽈꽉꽝꽤꽥꽹꾀꾄꾈꾳꾸꾹꾼꿀꿇꿈꿉꿋꿍꿎꿔꿨꿩꿰꿴꿸뀄뀌뀐뀔뀜뀝끄끈끊끌끓끔끕끗끙끝끼끽낀낄낌낍낑나낙낚난낟날낡남납낫났낭낮낯낱낳내낵낸낼냄냅냇냈냉냐냑냔냘냠냥너넉넋넌널넒넓넘넙넛넜넝넣네넥넨넬넴넵넷넸넹녀녁년녈념녔녕녘녜녠노녹논놀놈놉놋농높놓놔놨뇄뇌뇐뇔뇜뇝뇨뇰뇽누눅눈눌눔눕눗눙눠눴뉘뉜뉠뉩뉴뉼늄늉느늑는늗늘늙늠늡능늦늪늬니닉닌닏닐님닙닛닝닢다닥닦단닫달닭닮닳담답닷당닺닻닼닿대댁댄댈댐댑댓댔댕댜더덕덖던덜덞덟덤덥덧덩덫덮데덱덴델뎀뎁뎃뎄뎅뎌뎐뎠뎬도독돈돋돌돍돎돔돕돗동돛돝돠돤돨돼됀됍됐되된될됨됩됫됬됭됴두둑둔둘둠둡둣둥둬뒀뒤뒨뒴뒷뒹듀듄듈듐듕드득든듣들듦듬듭듯등듸디딕딘딛딜딤딥딧딨딩딪딫따딱딴딸땀땁땃땄땅땋때땐땔땜땠땡떄떠떡떤떨떫떱떳떴떵떻떼뗀뗄뗍뗏뗐뗑또똑똘똠똥똬뙈뙜뙤뚜뚝뚠뚤뚫뚱뛰뛴뛸뜀뜁뜨뜩뜬뜯뜰뜸뜹뜻띄띈띌띔띕띠띡띤띨띱띵라락란랄람랍랏랐랑랖랗래랙랜랠램랩랫랬랭랴략랸량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렜렝려력련렬렴렵렷렸령례롄로록론롣롤롬롭롯롱롹뢰뢴룀룅료룝룟룡루룩룬룰룸룹룻룽뤄뤘뤠뤼뤽륄륌륍륑류륙륜률륨륩륫륭르륵른를름릅릇릉릍릎릐리릭린릴림립릿링마막만많맏말맑맘맙맛망맞맟맡맣매맥맨맬맴맵맷맸맹맺먀먄먕머먹먼멀멈멉멋멍멎멓메멕멘멜멤멥멧멨멩며멱면멸몃몄명몆몇몐모목몫몬몰몸몹못몽뫼묀묄묏묘묠묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭐뭔뭘뭡뭣뮈뮌뮐뮤뮨뮬뮴므믄믈믐믓믜미믹민믿밀밈밉밋밌밍밎및밑바박밖반받발밝밟밤밥밧방밭배백밴밸뱀뱁뱃뱄뱅뱉뱌뱡버벅번벋벌범법벗벙벚벛베벡벤벧벨벰벳벴벵벼벽변별볍볏볐병볕볜보복볶본볼봄봅봇봉봐봣봤봬뵀뵈뵌뵐뵙뵤부북분붇불붉붐붑붓붕붙뷔뷧뷰뷴뷸븀브븐블븕비빅빈빌빍빔빕빗빙빚빛빠빡빤빨빰빱빳빴빵빻빼빽뺀뺄뺌뺍뺏뺐뺑뺨뺵뻐뻑뻔뻗뻘뻣뻤뻥뻬뼈뼉뼘뼛뽀뽁뽄뽈뽐뽑뽕뾰뿅뿌뿍뿐뿔뿜뿡쁘쁜쁠쁨쁩삐삑삔삘사삭삯산살삵삶삻삼삽삿샀상샅새색샌샐샘샙샛샜생샤샥샨샬샴샵샷샹샾섀섐섕서석섞선섣설섦섬섭섯섰성섶세섹센셀셈셉셋셌셍셔션셜셤셧셨셩셰셱셴셸솀솅소속솎손솔솜솝솟송솥솨솽쇄쇠쇤쇳쇼숀숄숍숏숑숖수숙순숟술숨숩숫숭숯숱숲숴쉈쉐쉑쉔쉘쉠쉥쉬쉰쉴쉼쉽쉿슁슈슉슌슐슘슙슛슝스슥슨슬슭슴습슷승슽시식신싣실싫심십싯싱싶싷싸싹싼쌀쌈쌉쌌쌍쌓쌔쌕쌤쌩쌰썅써썩썬썰썸썹썼썽쎄쎈쎌쎙쏘쏙쏜쏟쏠쏨쏩쏭쏴쐈쐐쐬쐰쐴쑈쑤쑥쑨쑹쒀쓰쓱쓴쓸쓺씀씁씌씐씨씩씬씰씸씹씻씽아악안앉않알앎앓암압앗았앙앚앞애액앤앨앰앱앳앴앵야약얀얄얇얌얍얏얐양얕얗얘어억언얹얻얼얽엄업없엇었엉엊엌엎에엑엔엘엠엡엣엥여역엮연열엷염엽엾엿였영옅옆옇예옌옐옘옙옛옜오옥온올옭옮옳옴옵옷옸옹옻와왁완왈왐왑왓왔왕왜왠왱외왼욀욋요욕욘욜욤욥욧용우욱운울움웁웃웅워웍원웓월웜웝웟웠웡웤웨웩웬웰웸웹웽위윅윈윌윔윕윗윙유육윤율윰윱윳융윷으윽윾은을읊음읍읏응읗의읜읩이익인읹일읽잃임입잇있잉잊잌잎자작잔잖잗잘잠잡잣잤장잦재잭잰잴잼잽잿쟀쟁쟈쟉쟌쟝쟤쟨저적전절젊젋점접젓젔정젖제젝젠젤젬젭젯젱져젹젼졋졌졍졘조족존졸좀좁종좆좇좋좌좍좔좡좨죄죈죌죔죗죠죡죤주죽준줄줌줍줏중줒줘줬줴쥐쥔쥘쥠쥬쥰쥴즈즉즌즐즘즙증지직진짇질짊짐집짓징짖짙짚짜짝짠짢짤짦짧짬짭짰짱째짹짼쨀쨈쨋쨌쨍쨩쩌쩍쩐쩔쩜쩝쩡쩨쪄쪘쪼쪽쫀쫄쫌쫑쫒쫓쫙쫴쬈쬐쬔쬘쬠쭈쭉쭌쭐쭘쭙쭝쭤쭸쮸쯔쯤쯩찌찍찎찐찔찜찝찟찡찢찧차착찬찮찰참찹찻찼창찾찿챃채책챈챌챔챕챗챘챙챠챤챦챨챱처척천철첨첩첫첬청체첵첸첼쳄쳇쳉쳐쳡쳤쳥초촉촌촐촘촙촛총촨촬촹최쵤쵸추축춘출춤춥춧충춰췄췌취췬췰츄츈츌츠측츤츨츰층치칙친칟칠칡칢침칩칫칭카칵칸칼캄캅캇캉캐캑캔캘캠캡캣캤캥캬커컥컨컫컬컴컵컷컸컹케켁켄켈켐켑켓켕켜켠켤켬켭켰코콕콘콜콤콥콧콩콰콱콴콸쾃쾅쾌쾨쾰쿄쿠쿡쿤쿨쿰쿱쿳쿵쿼퀀퀄퀏퀘퀜퀠퀭퀴퀵퀸퀼큅큇큐큘큠크큰클큼큽킁키킥킨킬킴킵킷킹타탁탄탈탉탐탑탓탔탕태택탠탤탬탭탯탰탱탸터턱턴털텀텁텃텄텅테텍텐텔템텝텟텡텨텼톄톈토톡톤톨톰톱톳통톺퇀퇘퇴툇툠투툭툰툴툼툽툿퉁퉈퉜퉤튀튄튈튐튑튕튜튠튤튬트특튼튿틀틈틉틋틔티틱틴틸팀팁팃팅파팍팎판팔팜팝팟팠팡팥패팩팬팰팸팹팻팼팽퍄퍅퍼퍽펀펄펌펍펏펐펑페펙펜펠펨펩펫펭펴편펼폄폈평폐포폭폰폴폼폽폿퐁퐈퐝푀푄푈표푯푸푹푼풀풂품풉풋풍퓌퓐퓨퓰퓸프픈플픔픕픙피픽핀필핌핍핏핑하학한할핥함합핫핬항해핵핸핼햄햅햇했행햋햐향헀허헉헌헐험헙헛헝헣헤헥헨헬헴헵헷헸헹혀혁현혈혐협혓혔형혜호혹혼홀홈홉홋홍홑화확환활홧황홱횃회획횔횟횡효횰후훅훈훌훑훔훗훙훠훤훨훼휀휑휘휙휜휠휨휩휴휸휼흄흉흐흑흔흗흘흙흝흠흡흥흩희흰흴히힉힌힐힘힙힛힝％＆．３＜＞ｇｍｘ～｢｣･\n"
     ]
    }
   ],
   "source": [
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9yejzNR7FIJt"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_english(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z0-9.,?!'\\s]\", '', text)   # Keep English, digits, punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()       # Normalize spaces\n",
    "    return text\n",
    "\n",
    "def clean_korean(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"[^가-힣0-9.,?!'\\s]\", '', text)  # Keep Korean, digits, punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()       # Normalize spaces\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df['English'] = df['English'].apply(clean_english)\n",
    "df['Korean'] = df['Korean'].apply(clean_korean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8qfcQ9GFJ_8",
    "outputId": "ebd575b4-36a6-41bd-b19e-31a982b59cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab:  !',.0123456789?abcdefghijklmnopqrstuvwxyz\n",
      "Korean vocab:  !',.0123456789?가각간갇갈갉감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰갱갸갹걀걍걔걘거걱건걷걸검겁것겄겅겆겉겊겋게겐겔겜겝겟겠겡겨격겪견결겸겹겼경곁계곗곘고곡곤곧골곪곯곰곱곳공곶과곽관괂괄괌괏광괘괜괭괴괵괸굉교굣굥구국군굳굴굵굶굼굽굿궁궂궃궈궉권궐궜궤궬궷귀귄귈귐귑귓규균귤그극근귿글긁금급긋긍기긱긴긷길김깁깃깄깅깊까깍깎깐깔깜깝깟깠깡깥깨깬깰깸깹깻깼깽꺄꺅꺌꺠꺼꺽꺾껀껄껌껍껏껐껑께껫껴꼈꼐꼬꼭꼰꼴꼼꼽꼿꽁꽂꽃꽈꽉꽝꽤꽥꽹꾀꾄꾈꾳꾸꾹꾼꿀꿇꿈꿉꿋꿍꿎꿔꿨꿩꿰꿴꿸뀄뀌뀐뀔뀜뀝끄끈끊끌끓끔끕끗끙끝끼끽낀낄낌낍낑나낙낚난낟날낡남납낫났낭낮낯낱낳내낵낸낼냄냅냇냈냉냐냑냔냘냠냥너넉넋넌널넒넓넘넙넛넜넝넣네넥넨넬넴넵넷넸넹녀녁년녈념녔녕녘녜녠노녹논놀놈놉놋농높놓놔놨뇄뇌뇐뇔뇜뇝뇨뇰뇽누눅눈눌눔눕눗눙눠눴뉘뉜뉠뉩뉴뉼늄늉느늑는늗늘늙늠늡능늦늪늬니닉닌닏닐님닙닛닝닢다닥닦단닫달닭닮닳담답닷당닺닻닼닿대댁댄댈댐댑댓댔댕댜더덕덖던덜덞덟덤덥덧덩덫덮데덱덴델뎀뎁뎃뎄뎅뎌뎐뎠뎬도독돈돋돌돍돎돔돕돗동돛돝돠돤돨돼됀됍됐되된될됨됩됫됬됭됴두둑둔둘둠둡둣둥둬뒀뒤뒨뒴뒷뒹듀듄듈듐듕드득든듣들듦듬듭듯등듸디딕딘딛딜딤딥딧딨딩딪딫따딱딴딸땀땁땃땄땅땋때땐땔땜땠땡떄떠떡떤떨떫떱떳떴떵떻떼뗀뗄뗍뗏뗐뗑또똑똘똠똥똬뙈뙜뙤뚜뚝뚠뚤뚫뚱뛰뛴뛸뜀뜁뜨뜩뜬뜯뜰뜸뜹뜻띄띈띌띔띕띠띡띤띨띱띵라락란랄람랍랏랐랑랖랗래랙랜랠램랩랫랬랭랴략랸량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렜렝려력련렬렴렵렷렸령례롄로록론롣롤롬롭롯롱롹뢰뢴룀룅료룝룟룡루룩룬룰룸룹룻룽뤄뤘뤠뤼뤽륄륌륍륑류륙륜률륨륩륫륭르륵른를름릅릇릉릍릎릐리릭린릴림립릿링마막만많맏말맑맘맙맛망맞맟맡맣매맥맨맬맴맵맷맸맹맺먀먄먕머먹먼멀멈멉멋멍멎멓메멕멘멜멤멥멧멨멩며멱면멸몃몄명몆몇몐모목몫몬몰몸몹못몽뫼묀묄묏묘묠묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭐뭔뭘뭡뭣뮈뮌뮐뮤뮨뮬뮴므믄믈믐믓믜미믹민믿밀밈밉밋밌밍밎및밑바박밖반받발밝밟밤밥밧방밭배백밴밸뱀뱁뱃뱄뱅뱉뱌뱡버벅번벋벌범법벗벙벚벛베벡벤벧벨벰벳벴벵벼벽변별볍볏볐병볕볜보복볶본볼봄봅봇봉봐봣봤봬뵀뵈뵌뵐뵙뵤부북분붇불붉붐붑붓붕붙뷔뷧뷰뷴뷸븀브븐블븕비빅빈빌빍빔빕빗빙빚빛빠빡빤빨빰빱빳빴빵빻빼빽뺀뺄뺌뺍뺏뺐뺑뺨뺵뻐뻑뻔뻗뻘뻣뻤뻥뻬뼈뼉뼘뼛뽀뽁뽄뽈뽐뽑뽕뾰뿅뿌뿍뿐뿔뿜뿡쁘쁜쁠쁨쁩삐삑삔삘사삭삯산살삵삶삻삼삽삿샀상샅새색샌샐샘샙샛샜생샤샥샨샬샴샵샷샹샾섀섐섕서석섞선섣설섦섬섭섯섰성섶세섹센셀셈셉셋셌셍셔션셜셤셧셨셩셰셱셴셸솀솅소속솎손솔솜솝솟송솥솨솽쇄쇠쇤쇳쇼숀숄숍숏숑숖수숙순숟술숨숩숫숭숯숱숲숴쉈쉐쉑쉔쉘쉠쉥쉬쉰쉴쉼쉽쉿슁슈슉슌슐슘슙슛슝스슥슨슬슭슴습슷승슽시식신싣실싫심십싯싱싶싷싸싹싼쌀쌈쌉쌌쌍쌓쌔쌕쌤쌩쌰썅써썩썬썰썸썹썼썽쎄쎈쎌쎙쏘쏙쏜쏟쏠쏨쏩쏭쏴쐈쐐쐬쐰쐴쑈쑤쑥쑨쑹쒀쓰쓱쓴쓸쓺씀씁씌씐씨씩씬씰씸씹씻씽아악안앉않알앎앓암압앗았앙앚앞애액앤앨앰앱앳앴앵야약얀얄얇얌얍얏얐양얕얗얘어억언얹얻얼얽엄업없엇었엉엊엌엎에엑엔엘엠엡엣엥여역엮연열엷염엽엾엿였영옅옆옇예옌옐옘옙옛옜오옥온올옭옮옳옴옵옷옸옹옻와왁완왈왐왑왓왔왕왜왠왱외왼욀욋요욕욘욜욤욥욧용우욱운울움웁웃웅워웍원웓월웜웝웟웠웡웤웨웩웬웰웸웹웽위윅윈윌윔윕윗윙유육윤율윰윱윳융윷으윽윾은을읊음읍읏응읗의읜읩이익인읹일읽잃임입잇있잉잊잌잎자작잔잖잗잘잠잡잣잤장잦재잭잰잴잼잽잿쟀쟁쟈쟉쟌쟝쟤쟨저적전절젊젋점접젓젔정젖제젝젠젤젬젭젯젱져젹젼졋졌졍졘조족존졸좀좁종좆좇좋좌좍좔좡좨죄죈죌죔죗죠죡죤주죽준줄줌줍줏중줒줘줬줴쥐쥔쥘쥠쥬쥰쥴즈즉즌즐즘즙증지직진짇질짊짐집짓징짖짙짚짜짝짠짢짤짦짧짬짭짰짱째짹짼쨀쨈쨋쨌쨍쨩쩌쩍쩐쩔쩜쩝쩡쩨쪄쪘쪼쪽쫀쫄쫌쫑쫒쫓쫙쫴쬈쬐쬔쬘쬠쭈쭉쭌쭐쭘쭙쭝쭤쭸쮸쯔쯤쯩찌찍찎찐찔찜찝찟찡찢찧차착찬찮찰참찹찻찼창찾찿챃채책챈챌챔챕챗챘챙챠챤챦챨챱처척천철첨첩첫첬청체첵첸첼쳄쳇쳉쳐쳡쳤쳥초촉촌촐촘촙촛총촨촬촹최쵤쵸추축춘출춤춥춧충춰췄췌취췬췰츄츈츌츠측츤츨츰층치칙친칟칠칡칢침칩칫칭카칵칸칼캄캅캇캉캐캑캔캘캠캡캣캤캥캬커컥컨컫컬컴컵컷컸컹케켁켄켈켐켑켓켕켜켠켤켬켭켰코콕콘콜콤콥콧콩콰콱콴콸쾃쾅쾌쾨쾰쿄쿠쿡쿤쿨쿰쿱쿳쿵쿼퀀퀄퀏퀘퀜퀠퀭퀴퀵퀸퀼큅큇큐큘큠크큰클큼큽킁키킥킨킬킴킵킷킹타탁탄탈탉탐탑탓탔탕태택탠탤탬탭탯탰탱탸터턱턴털텀텁텃텄텅테텍텐텔템텝텟텡텨텼톄톈토톡톤톨톰톱톳통톺퇀퇘퇴툇툠투툭툰툴툼툽툿퉁퉈퉜퉤튀튄튈튐튑튕튜튠튤튬트특튼튿틀틈틉틋틔티틱틴틸팀팁팃팅파팍팎판팔팜팝팟팠팡팥패팩팬팰팸팹팻팼팽퍄퍅퍼퍽펀펄펌펍펏펐펑페펙펜펠펨펩펫펭펴편펼폄폈평폐포폭폰폴폼폽폿퐁퐈퐝푀푄푈표푯푸푹푼풀풂품풉풋풍퓌퓐퓨퓰퓸프픈플픔픕픙피픽핀필핌핍핏핑하학한할핥함합핫핬항해핵핸핼햄햅햇했행햋햐향헀허헉헌헐험헙헛헝헣헤헥헨헬헴헵헷헸헹혀혁현혈혐협혓혔형혜호혹혼홀홈홉홋홍홑화확환활홧황홱횃회획횔횟횡효횰후훅훈훌훑훔훗훙훠훤훨훼휀휑휘휙휜휠휨휩휴휸휼흄흉흐흑흔흗흘흙흝흠흡흥흩희흰흴히힉힌힐힘힙힛힝\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all rows into single string per language\n",
    "english_text = ''.join(df['English'])\n",
    "korean_text = ''.join(df['Korean'])\n",
    "\n",
    "# Get sorted unique characters\n",
    "eng_vocab = ''.join(sorted(set(english_text)))\n",
    "kor_vocab = ''.join(sorted(set(korean_text)))\n",
    "\n",
    "print(\"English vocab:\", eng_vocab)\n",
    "print(\"Korean vocab:\", kor_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4C_a-thDFSsN"
   },
   "outputs": [],
   "source": [
    "# English Tokenizer\n",
    "\n",
    "vocabulary_size = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer_English = tf.keras.layers.TextVectorization(max_tokens=vocabulary_size, output_sequence_length=max_len)\n",
    "tokenizer_English.adapt(df[\"English\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "xiacFFx3FVlE"
   },
   "outputs": [],
   "source": [
    "# Korean Tokenizer\n",
    "\n",
    "vocabulary_size = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer_Korean = tf.keras.layers.TextVectorization(max_tokens=vocabulary_size, output_sequence_length=max_len)\n",
    "tokenizer_Korean.adapt([f\"SOS {s} EOS\" for s in df['Korean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nSEE201UFX0Y"
   },
   "outputs": [],
   "source": [
    "X_train = tokenizer_English(df['English'][:1_000_000])\n",
    "X_valid = tokenizer_English(df['English'][1_000_000:])\n",
    "X_train_dec = tokenizer_Korean([f\"SOS {s}\" for s in df['Korean'][:1_000_000]])\n",
    "X_valid_dec = tokenizer_Korean([f\"SOS {s}\" for s in df['Korean'][1_000_000:]])\n",
    "\n",
    "Y_train = tokenizer_Korean([f\"{s} EOS\" for s in df['Korean'][:1_000_000]])\n",
    "Y_valid = tokenizer_Korean([f\"{s} EOS\" for s in df['Korean'][1_000_000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LNFRvqhMF2VC"
   },
   "outputs": [],
   "source": [
    "def map_fn(inputs, target):\n",
    "    # inputs = (X_train, X_train_dec) -- X_train_dec is full target sequence with SOS and EOS tokens\n",
    "    encoder_input, full_target = inputs\n",
    "    # Split decoder input and target for teacher forcing\n",
    "    decoder_input = full_target[:, :-1]\n",
    "    decoder_target = full_target[:, 1:]\n",
    "    return (encoder_input, decoder_input), decoder_target\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(((X_train, X_train_dec), Y_train))\n",
    "train_dataset = train_dataset.shuffle(1000).batch(BATCH_SIZE).map(map_fn).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(((X_valid, X_valid_dec), Y_valid))\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE).map(map_fn).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yt_ZqtoIGif_"
   },
   "outputs": [],
   "source": [
    "# Vocabulary sizes\n",
    "input_vocab_size = len(tokenizer_English.get_vocabulary())\n",
    "target_vocab_size = len(tokenizer_Korean.get_vocabulary())\n",
    "\n",
    "# Positional encoding max lengths (same as tokenizer max length)\n",
    "max_positional_encoding_input = 100\n",
    "max_positional_encoding_target = 100\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=4,\n",
    "    embedding_dim=256,\n",
    "    num_heads=8,\n",
    "    fully_connected_dim=1024,\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    max_positional_encoding_input=max_positional_encoding_input,\n",
    "    max_positional_encoding_target=max_positional_encoding_target,\n",
    "    dropout_rate=0.1,\n",
    "    layernorm_eps=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "56IE56JlGfYI"
   },
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "ayjBYZhmGhcH",
    "outputId": "54ff8fee-0140-40aa-9804-b476023272f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'decoder_layer_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'decoder_layer_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'decoder_layer_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'decoder_layer_7', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  932/15625\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:14:20\u001b[0m 549ms/step - accuracy: 0.8836 - loss: 1.2736"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1687446657.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = transformer.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# because it takes to much time to train the model for n epoch I trained on 1 epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     callbacks=[\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[1;32m    220\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = transformer.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=1, # because it takes to much time to train the model for n epoch I trained on 1 epoch\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "6w5SrvrTRuUu"
   },
   "outputs": [],
   "source": [
    "korean_sentences_with_tokens = [f\"SOS {s} EOS\" for s in df['Korean']]\n",
    "\n",
    "temp_tokenizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size - 4,\n",
    "    output_sequence_length=max_len\n",
    ")\n",
    "temp_tokenizer.adapt(korean_sentences_with_tokens)\n",
    "\n",
    "raw_vocab = temp_tokenizer.get_vocabulary()\n",
    "special_tokens = [\"\", \"[UNK]\", \"SOS\", \"EOS\"]\n",
    "final_vocab = special_tokens + [token for token in raw_vocab if token not in special_tokens]\n",
    "\n",
    "tokenizer_Korean = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size,\n",
    "    output_sequence_length=max_len,\n",
    "    vocabulary=final_vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "QClMBKs3RyPL"
   },
   "outputs": [],
   "source": [
    "vocab = tokenizer_Korean.get_vocabulary()\n",
    "sos_id = vocab.index(\"SOS\")\n",
    "eos_id = vocab.index(\"EOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "dLBUh6DESvrV"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, transformer, tokenizer_English, tokenizer_Korean, max_target_len=100):\n",
    "    encoder_input = tf.cast(tokenizer_English([sentence]), tf.int32)\n",
    "    vocab = tokenizer_Korean.get_vocabulary()\n",
    "    sos_id = vocab.index(\"SOS\")\n",
    "    eos_id = vocab.index(\"EOS\")\n",
    "    decoder_input = tf.convert_to_tensor([[sos_id]], dtype=tf.int32)\n",
    "\n",
    "    for _ in range(max_target_len):\n",
    "        predictions = transformer([encoder_input, decoder_input], training=False)\n",
    "        predicted_id = tf.argmax(predictions[:, -1:, :], axis=-1)\n",
    "        predicted_id = tf.cast(predicted_id, tf.int32)\n",
    "        decoder_input = tf.concat([decoder_input, predicted_id], axis=-1)\n",
    "        if predicted_id[0][0].numpy() == eos_id:\n",
    "            break\n",
    "\n",
    "    output_tokens = decoder_input.numpy()[0][1:]\n",
    "    id_to_word = dict(enumerate(tokenizer_Korean.get_vocabulary()))\n",
    "    translated_tokens = [id_to_word[i] for i in output_tokens if i != eos_id]\n",
    "    return \" \".join(translated_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlnOk4xlT9-S"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Achieved 88% accuracy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
